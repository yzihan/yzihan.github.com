(this["webpackJsonpzihan-site"]=this["webpackJsonpzihan-site"]||[]).push([[0],{283:function(e,t,i){"use strict";i.r(t);var a,n=i(0),r=i(1),s=i.n(r),o=i(37),c=(i(56),i(23)),l=i(7),d=i(24),h=i(13),g=i(28),b=i(6),u=i(4),p=i.p+"static/media/placeholder.19e90386.gif",m=i.p+"static/media/loading.ccdf9915.gif",j=i(288),f=i(286),x=i(10),v=i.p+"static/media/logo.103b5fa1.svg",O=i(47),y=i(287),w=[600,800,1e3,1200,1/0],k=function(e){return w[e]},C=function(e){return e&&w[e-1]||300},S=s.a.createContext(0);function N(e){var t=e.value,i=e.args,a=e.varName,r=Object(d.a)(e,["value","args","varName"]);return Object(n.jsx)(y.a,Object(l.a)(Object(l.a)({language:"javascript",showLineNumbers:!0},r),{},{children:(a?a+" = ":"")+JSON.stringify.apply(JSON,[t].concat(Object(O.a)(i||[null,2])))}))}var T={"":function(){return Object(n.jsxs)(Se,{title:"Debug Page",children:[Object(n.jsx)(D,{}),Object(n.jsxs)("p",{children:["Width Level: ",Object(n.jsx)(S.Consumer,{children:function(e){return e.toString()}})]}),Object(n.jsx)(N,{value:Object({NODE_ENV:"production",PUBLIC_URL:"",WDS_SOCKET_HOST:void 0,WDS_SOCKET_PATH:void 0,WDS_SOCKET_PORT:void 0,FAST_REFRESH:!0}),varName:"process.env"})]})},pdf:function(){I(),Object(r.useRef)(null);var e=Object(r.useState)("/data/cv.pdf"),t=Object(c.a)(e,2),i=t[0];t[1];return Object(n.jsxs)(Se,{title:"PDF Debug",children:[Object(n.jsx)(D,{}),Object(n.jsxs)("fieldset",{children:[Object(n.jsx)("legend",{children:"PDF Data"}),void 0,Object(n.jsx)("a",{href:i,target:"_blank",rel:"noreferrer",children:"Open in new window"})]}),"Rendered:"]})},default:function(){var e=E();return Object(n.jsx)(Se,{title:"React App",className:e.outerContainer,children:Object(n.jsxs)("header",{className:e.app,children:[Object(n.jsx)("img",{src:v,className:[e.appLogo,e.appLogoSpining].join(" "),alt:"logo"}),Object(n.jsxs)("p",{children:["Edit ",Object(n.jsx)("code",{children:"src/App.tsx"})," and save to reload."]}),Object(n.jsx)(b.b,{to:"/debug/test",className:e.appLink,children:"View Test"}),Object(n.jsxs)(b.b,{to:"/debug/",className:e.appLink,children:["Back to ",Object(n.jsx)("code",{children:"/debug/"})]})]})})},test:function(){var e=E();return Object(n.jsx)(Se,{title:"Hello, React App!",className:e.outerContainer,children:Object(n.jsxs)("header",{className:e.app,children:[Object(n.jsx)("img",{src:m,className:e.appLogo,alt:"logo"}),Object(n.jsx)("p",{children:"This is test page!"}),Object(n.jsx)(b.b,{to:"/debug/default",className:e.appLink,children:"View Debug Page"}),Object(n.jsxs)(b.b,{to:"/debug/",className:e.appLink,children:["Back to ",Object(n.jsx)("code",{children:"/debug/"})]})]})})}};function A(){var e=[];for(var t in T){var i="/debug/".concat(t);e.push(Object(n.jsx)(u.b,{exact:!0,path:i,component:T[t]},i))}return e.push(Object(n.jsx)(u.b,{path:"/debug/",render:function(){return Object(n.jsx)(u.a,{to:"/debug/"})}},"wildcard")),e}function D(e){var t=[];for(var i in T){var a="/debug/".concat(i);t.push(Object(n.jsx)("li",{children:Object(n.jsx)(b.b,Object(l.a)(Object(l.a)({},e),{},{to:a,children:a}))},a))}return Object(n.jsxs)(s.a.Fragment,{children:[Object(n.jsx)("h2",{style:{marginTop:0},children:"Debug Pages"}),Object(n.jsx)(b.b,Object(l.a)(Object(l.a)({},e),{},{to:"/",children:"Back to app index"})),Object(n.jsx)("ul",{children:t})]})}var I=Object(x.a)({viewer:{maxWidth:"600px",margin:[[0,"auto"]]}});var E=Object(x.a)({"@keyframes App-logo-spin":{from:{transform:"rotate(0deg)"},to:{transform:"rotate(360deg)"}},appLogo:Object(h.a)({height:"40vmin",pointerEvents:"none"},"@media (max-width: ".concat(C(0),"px)"),{height:.4*C(0)}),appLogoSpining:{"@media (prefers-reduced-motion: no-preference)":{animation:"$App-logo-spin infinite 20s linear"}},outerContainer:{backgroundColor:"#282c34"},app:(a={minHeight:"100vh",display:"flex",flexDirection:"column",alignItems:"center",justifyContent:"center",fontSize:"calc(10px + 2vmin)"},Object(h.a)(a,"@media (max-width: ".concat(C(0),"px)"),{fontSize:10+.02*C(0)}),Object(h.a)(a,"color","white"),Object(h.a)(a,"textAlign","center"),a),appLink:{color:"#61dafb"}});Object(x.a)({outerContainer:{},page:{background:"white",color:"black",textAlign:"center",display:"flex",flexDirection:"column",justifyContent:"center",padding:[[0,30]]},infoBlock:{textAlign:"left"}});var z=i.p+"static/media/bio.61dbeff3.png",W=i.p+"static/media/material-art.670e8f9c.jpg",L=i.p+"static/media/cali1.e244eebf.jpg",P=i.p+"static/media/cali2.a5b357a8.jpg",H=i.p+"static/media/painting1.1e3a0c6c.jpg",R=i.p+"static/media/sketch1.42ed6f25.jpg",Y=i.p+"static/media/sketch2.3765bc77.jpg",F=i.p+"static/media/argaze.fb7bce3f.jpg",B=i.p+"static/media/towards.8d09635d.png",Z=i.p+"static/media/speechin.7257c7d7.jpg",U=i.p+"static/media/reducing.688cac44.png",M=i.p+"static/media/inthemaking.b7fd6a6b.png",q=i.p+"static/media/enabling.16484fd5.jpg",_=i.p+"static/media/gender.4491d26b.jpg",G=i.p+"static/media/argaze2.eecb2be9.png",V=i.p+"static/media/towards2.6021ae32.png",J=i.p+"static/media/speechin2.60718949.png",K=i.p+"static/media/reducing2.7eb70db1.png",X=i.p+"static/media/inthemaking2.a930cc79.png",$=i.p+"static/media/enabling2.c8c0a939.png",Q=i.p+"static/media/gender2.612183e8.png",ee=i.p+"static/media/bamboo.2bc0fdde.jpg",te=i.p+"static/media/tibetan.96b63814.jpg",ie=i.p+"static/media/headset.9bfeb0db.jpg",ae=i.p+"static/media/cognitive.caab71be.png",ne=i.p+"static/media/bamboo2.55ae7ba6.png",re=i.p+"static/media/logo-zju.b838d026.png",se=i.p+"static/media/logo-nus.203ac757.png",oe=i.p+"static/media/logo-cornell.b60d1552.png",ce=i.p+"static/media/logo-ucla.e6394d80.png",le=[{logo:re,name:"Zhejiang University",abbr:"ZJU",lab:"CDC Lab",supervisor:"Dr. Xiangdong Li",coadvisor:"Dr. Preben Hansen",laburl:void 0,surl:"https://person.zju.edu.cn/en/andolxli",curl:"https://hansen.blogs.dsv.su.se/"},{logo:se,name:"National University of Singapore",abbr:"NUS",lab:"NUS-HCI Lab",supervisor:"Dr. Shengdong Zhao",coadvisor:"Dr. Wei-Tsang Ooi",laburl:"\u201dhttp://www.nus-hci.org/",surl:"http://www.shengdongzhao.com",curl:"https://www.comp.nus.edu.sg/~ooiwt/"},{logo:oe,name:"Cornell University",abbr:"Cornell",lab:"SciFi Lab",supervisor:"Dr. Cheng Zhang",coadvisor:"Dr. Shiri Azenkot",laburl:"https://www.scifilab.org/",surl:"http://www.czhang.org/",curl:"http://www.shiriazenkot.com/"},{logo:ce,name:"University of California, Los Angeles",abbr:"UCLA",lab:"UCLA HCI Research",supervisor:"Dr. Xiang 'Anthony' Chen",coadvisor:"Dr. Yang Zhang",laburl:"https://hci.ucla.edu/",surl:"https://xac.is/",curl:"https://yangzhang.dev/"}],de=[{name:"Sensing & Interaction Techniques"},{name:"Moment-to-Moment Continuous Attention Fluctuation Monitoring through Consumer-Grade EEG Device",shortName:"towards",previewImg:B,image:V,writer:"Shan Zhang*, Zihan Yan*, Shardul Sapkota, Shengdong Zhao, Wei-Tsang Ooi, Ye Qiyuan",label:"Sensors MDPI",abstract:"While numerous studies have explored using various sensing techniques to measure attention states, moment-to-moment attention fluctuation measurement is unavailable. To bridge this gap, we applied a novel paradigm in psychology, the gradual-onset continuous performance task (gradCPT), to collect the ground truth of attention states. GradCPT allows for the precise labeling of attention fluctuation on an 800ms time scale. We then developed a new technique for measuring continuous attention fluctuation, based on a machine learning approach that uses the spectral properties of EEG signals as the main features. We demonstrated that, even using a consumer grade EEG device, the detection accuracy of moment-to-moment attention fluctuations was 73.49%. Next, we empirically validated our technique in a video learning scenario and found that our technique match with the classification obtained through thought probes, with an average F1 score of 0.77. Our results suggest the effectiveness of using gradCPT as a ground truth labeling method and the feasibility of using consumer-grade EEG devices for continuous attention fluctuation detection.",doi:"10.3390/s21103419",pdf:"sensors-21-03419-v2.pdf"},{name:"SpeeChin: A Smart Necklace for Silent Speech Recognition",shortName:"speechin",previewImg:Z,image:J,writer:"Ruidong Zhang, Mingyang Chen, Benjamin Steeper, Yaxuan Li, Zihan Yan, Yizhuo Chen, Songyun Tao, Tuochao Chen, Hyunchul Lim, Cheng Zhang",status:"Submitted",label:"IMWUT2021",abstract:"This paper presents SpeeChin, a smart necklace that can recognize 54 English and 44 Chinese silent speech commands. A customized infrared (IR) imaging system is mounted on a necklace to capture images of the neck and face from under the chin. These images are first pre-processed and then deep learned by an end-to-end deep convolutional-recurrent-neural-network (CRNN) model to infer different silent speech commands. A user study with 20 participants (10 participants for each language) showed that SpeeChin could recognize 54 English and 44 Chinese silent speech commands with average cross-session accuracies of 90.5% and 91.6%, respectively. To further investigate the potential of SpeeChin in recognizing other silent speech commands, we conducted another study with 10 participants distinguishing between 72 one-syllable nonwords. Based on the results from the user studies, we further discuss the challenges and opportunities of deploying SpeeChin in real-world applications."},{name:"ARGaze: A Dataset of Eye Gaze Images for Calibration-Free Eye Tracking with Augmented Reality Headset",shortName:"argaze",previewImg:F,image:G,writer:"Zihan Yan, Yue Wu, Yifei Shan, Wenqian Chen, Xiangdong Li",status:"Submitted",label:"Journal of Nature-Scientific Data",abstract:"Eye-tracking is a widespread method in human-computer interaction. However, it is often criticised for the troublesome calibration with new users and scenes. Despite progress in machine learning-based eye tracking, preparing a qualified dataset remains challenging. We present ARGaze, a dataset of eye gaze images, for calibration-free eye tracking with AR headset. The dataset was derived from 25 participants who conducted eye gaze tasks in augmented reality and real-world scenes for approximately 30min. It comprises 1,321,968 pairs of eye images and corresponding world view in 50 videos. To validate the dataset, we implemented the SIFTNet- and ALSTM-FCN-hybrid model and compared the results with that of the state-of-the-art research. The results show that the dataset is of high compatibility with different machine learning models and it contains sufficient eye gaze-related features that enable the record low eye gaze estimation error by 3.70degree on average and 1.56degree on specific participant, without involving any pre-study calibrations across the participants. Guidance for dataset reuse and related implications for eye tracking design and evaluation are described."},{name:"Human Perception Measurement & Modeling"},{name:"Reducing Cognitive Loads in Parcel Scanning with Eye Tracking-based Augmented Reality Headset",shortName:"reducing",previewImg:U,image:K,writer:"Zihan Yan, Yufei Wu, Yiyang Li, Yifei Shan, Preben Hansen, Xiangdong Li",status:"Submitted",label:"Interacting with Computers",abstract:"Parcel scanning in warehouse is a highly frequent task that consists of multiple processes e.g. barcode seeking and scanning, scan result confirming, and parcel relocating. It is cognitively demanding as each process involves a respective level of cognitive loads and fluctuation of cognitive loads would quickly deteriorate human workers\u2019 productivity. Despite many wearable devices were devised for efficiency of parcel scanning, few are aimed at eliminating cognitive loads. We developed the eye tracking-based augmented reality headset with foveated vision detection and smooth pursuit to leverage parallel parcel barcode seeking-scanning and spontaneous scan result confirming, respectively. We recruited 33 participants to investigate how the headset influenced cognitive loads. The results show that the headset maintained high scanning efficiency and lower cognitive loads across the tasks with varying difficulties and it significantly reduced the participants\u2019 cognitive loads during the processes of barcode seeking and scanning and result confirmation. The headset also demonstrated good usability and ease of use."},{name:"Gender Differences of Cognitive Loads in Augmented Reality-based Warehouse",shortName:"gender",previewImg:_,image:Q,writer:"Zihan Yan, Yifei Shan, Kailin Yin, Yiyang Li, Xiangdong Li",label:"Conference Paper A, IEEE VR 2021",abstract:"The rapid emergence of augmented reality (AR) has brought considerable advantages to warehouse workers. However, due to inherent biological and cognitive differences, the male and female workers perceive cognitive loads differently. Understanding the differences is essential to improve the workers\u2019 productivity and well-being. Therefore, we developed the AR headset that helped participants facilitate parcel scanning and evaluated the gender differences in the context of long-lasting repetitive parcel scanning. The results show that the female workers had significantly lower operational efficiency, higher visual attention, and higher memory loads than the male, but they quickly gained advantages in these aspects.",doi:"10.1109/VRW52623.2021.00132",pdf:"09419249.pdf"},{name:"Intelligent User Interfaces"},{name:"Design and Evaluation of a Distance-Driven User Interface for Asynchronous Collaborative Exhibit Browsing in an Augmented Reality Museum",shortName:"enabling",previewImg:q,image:$,writer:"Wenqian Chen, Yifei Shan, Yue Wu, Zihan Yan, Xiangdong Li",label:"IEEE Access",abstract:"Augmented reality museums allow visitors to jointly view and interact with exhibits. However, real-time exhibit browsing does not accommodate latecomers to museums and offers limited support to temporally separated visitors. To stimulate asynchronous exhibit browsing, we developed a distance-driven user interface that divided the augmented reality exhibit-egocentric space into four distance ranges, each having a set of social networking features and different privileges for exhibit viewing and interaction. The user interface enables asynchronous exhibit browsing for visitors participating at different times. We conducted empirical studies to evaluate how the user interface affected visitors\u2019 collaborative exhibit browsing in terms of perceived usability and learning gains. The results show that the perceived usability of the user interface is consistently high across all distance ranges. The user interface stimulates collaborative exhibit browsing with significant improvements in learning efficiency and learning attention durations, although learning satisfaction showed no difference across the participants. Implications for how the distance-driven user interface can be generalised for other interactive applications are discussed.",doi:"10.1109/ACCESS.2021.3080286",pdf:"09431194.pdf"},{name:"In the Making of Eye Tracking-enabled Augmented Reality Headset",shortName:"inthemaking",previewImg:M,image:X,writer:"Xiangdong Li, Yue Wu, Yifei Shan, Zihan Yan, Wenqian Chen, Qiuyi Yang",status:"Submitted",label:"Multimedia Tools and Applications",abstract:"The changes of mixed reality technology are happening in the industry at a record pace and eye tracking has become a new frontier in understanding user\u2019s attentional behaviours in mixed reality context. Despite several mixed reality systems integrated eye tracking add-on, few of these studies systematically tackled ease of assembly of the devices. Therefore, we developed the ETGaze, an ease of assembly eye tracking device for mixed reality study and evaluated its ease of assembly with respect to perceived usability, reliability, and generalisability. The results show that users took 22.87sec approximately for full assembly of the device, which is 2.9 times faster than the time of assembling the Holokit. The participants reported 8.27 out of 10 overall satisfaction and over 80% reported the ETGaze assembly was easier than Holokit. The device reached 1.02degree and 1.30degree estimation error in augmented reality and real-world scenes, respectively. Implications for how generalising the device could be used in other mixed reality contexts are discussed."}];function he(){var e=ue();return Object(n.jsxs)(n.Fragment,{children:[Object(n.jsx)("h3",{className:e.secHdr,children:"International Competition"}),Object(n.jsxs)(we,{src:ee,alt:"bamboo",children:[Object(n.jsx)(b.b,{to:"/design/bamboo.html","data-stay-black":!0,children:Object(n.jsx)("h3",{children:"Bamboo Shoot (A Soil Remediation Product Used Industrial Wastes)"})}),Object(n.jsx)("p",{children:Object(n.jsx)("span",{className:[e.labels,e.cyan].join(" "),children:"iF Design Talent Award 2020"})})]}),Object(n.jsx)("h3",{className:e.secHdr,children:"Patents for Invention"}),Object(n.jsxs)(we,{src:te,alt:"tibetan",children:[Object(n.jsx)("h3",{children:"A Tibetan Dance Shoe with Pattern Projection Function"}),Object(n.jsx)("p",{children:Object(n.jsx)("span",{className:[e.labels,e.red].join(" "),children:"CN 110710755 A"})}),Object(n.jsx)("p",{})]}),Object(n.jsxs)(we,{src:ie,alt:"headset",children:[Object(n.jsx)("h3",{children:"An Eye-tracking based calibration-free AR headset design for picking task in warehouse"}),Object(n.jsx)("p",{children:Object(n.jsx)("span",{className:[e.labels,e.orange].join(" "),children:"Pending"})})]}),Object(n.jsxs)(we,{src:ae,alt:"cognitive",children:[Object(n.jsx)("h3",{children:"Cognitive Load and Fatigue Detection Method and Device in Order Picking Tasks."}),Object(n.jsx)("p",{children:Object(n.jsx)("span",{className:[e.labels,e.orange].join(" "),children:"Pending"})})]})]})}var ge=Object(x.a)({out:{display:"flex",flexDirection:"row",flexWrap:"wrap",justifyContent:"center","& a":{color:"black"}},card:{padding:[[30,0,0,0]],width:"250px",textAlign:"center","& h3":{margin:[[15,0]]}},supervised:{display:"block",fontSize:"1rem",margin:[[10,0]],"&::before":{display:"block",fontSize:"0.7rem",fontStyle:"italic",content:'"Supervised By"'}},coadv:{fontSize:"0.95rem",display:"block",margin:[[10,0]],"&::before":{display:"block",fontSize:"0.7rem",fontStyle:"italic",content:'"Co-advised By"'}}});function be(){var e=ge();return Object(n.jsx)("div",{className:e.out,children:le.map((function(t){return Object(n.jsxs)("div",{className:e.card,children:[Object(n.jsx)("img",{src:t.logo,width:"100",height:"100"}),t.laburl?Object(n.jsx)("a",{href:t.laburl,children:Object(n.jsxs)("h3",{children:[t.lab," @ ",Object(n.jsx)("abbr",{title:t.name,children:t.abbr})]})}):Object(n.jsxs)("h3",{children:[t.lab," @ ",Object(n.jsx)("abbr",{title:t.name,children:t.abbr})]}),Object(n.jsx)("a",{href:t.surl,children:Object(n.jsx)("span",{className:e.supervised,children:t.supervisor})}),Object(n.jsx)("a",{href:t.curl,children:Object(n.jsx)("span",{className:e.coadv,children:t.coadvisor})})]})}))})}var ue=Object(x.a)({labels:{display:"inline-block",borderRadius:3,border:"1px solid #333",padding:[[3,8]],margin:[[0,0,0,10]],fontSize:"small"},secHdr:{margin:[[30,0,10,0]]},green:{color:"#52c41a",background:"#f6ffed",borderColor:"#b7eb8f"},orange:{color:"#fa8c16",background:"#fff7e6",borderColor:"#ffd591"},gold:{color:"#faad14",background:"#fffbe6",borderColor:"#ffe58f"},cyan:{color:"#13c2c2",background:"#e6fffb",borderColor:"#87e8de"},red:{color:"#f5222d",background:"#fff1f0",borderColor:"#ffa39e"}});function pe(){var e=ue();return Object(n.jsx)(n.Fragment,{children:de.map((function(t){return t.shortName?Object(n.jsxs)(we,{src:t.previewImg,alt:t.shortName,children:[Object(n.jsx)(b.b,{to:"/publication/".concat(t.shortName,".html"),"data-stay-black":!0,children:Object(n.jsx)("h3",{children:t.name})}),Object(n.jsx)("p",{children:t.writer.split("Zihan Yan",2).reduce((function(e,t){return"string"===typeof e?[e,Object(n.jsx)("span",{style:{fontWeight:"bold"},children:"Zihan Yan"},"name"),t]:e.concat([Object(n.jsx)("span",{style:{fontWeight:"bold"},children:"Zihan Yan"},"name"),t])}))}),Object(n.jsxs)("p",{children:[Object(n.jsx)("span",{className:[e.labels,e.green].join(" "),children:t.label}),t.doi?Object(n.jsxs)(n.Fragment,{children:[Object(n.jsx)("a",{href:"/data/pdf/"+t.pdf,target:"_blank",children:Object(n.jsx)("span",{style:{float:"right"},className:[e.labels,e.red].join(" "),children:"PDF"})}),Object(n.jsx)("a",{href:"https://doi.org/"+t.doi,target:"_blank",children:Object(n.jsx)("span",{style:{float:"right"},className:[e.labels,e.orange].join(" "),children:"DOI"})})]}):Object(n.jsx)("span",{style:{float:"right"},className:[e.labels,"Accepted"===t.status?e.red:e.gold].join(" "),children:t.status})]})]},t.shortName):Object(n.jsx)("h3",{className:e.secHdr,children:t.name})}))})}var me,je=Object(l.a)(Object(l.a)({"/":{title:"Home",shortTitle:"Home",component:function(){return Object(n.jsxs)(Se,{title:"Home",children:[Object(n.jsx)("h2",{children:"About me"}),Object(n.jsxs)(we,{src:z,alt:"bio",allowLargeImage:!0,children:[Object(n.jsx)("h3",{children:"Hi! You can call me Zihan"}),Object(n.jsxs)("p",{children:["I am an undergraduate from Zhejiang University, major in industrial design of Computer Science College and minor in the advanced education engineering class of CHU KOCHEN Honors college. I am doing research in ",Object(n.jsx)("a",{href:"https://hci.ucla.edu/",children:"UCLA HCI Research"}),", advised by ",Object(n.jsx)("a",{href:"https://xac.is/",children:"Dr. Xiang 'Anthony' Chen"})," and ",Object(n.jsx)("a",{href:"https://yangzhang.dev/",children:"Dr. Yang Zhang"}),". I also work closely with ",Object(n.jsx)("a",{href:"http://www.czhang.org/",children:"Dr. Cheng Zhang"})," in ",Object(n.jsx)("a",{href:"https://www.scifilab.org/",children:"SciFi Lab"}),"\xa0of\xa0Cornell University."]}),Object(n.jsx)("p",{children:"My research interests lie in\xa0human-computer interaction,\xa0ubiquitous computing, and\xa0cognitive psychology. To be specific, my past projects are about about Sensing & Interaction Techniques, Human Perception Measurement & Modeling and Intelligent User Interfaces. Coming from multi-disciplinary backgrounds, I pursue to further facilitate human-to-human communication by combining machine intelligence and artificial intelligence."}),Object(n.jsx)("p",{children:"I am applying for a PhD program 2022fall. You can check in my\xa0CV\xa0for further information."})]}),Object(n.jsx)("h2",{children:"Research Experience"}),Object(n.jsx)(be,{}),Object(n.jsx)("h2",{children:"Publication"}),Object(n.jsx)(pe,{}),Object(n.jsx)("h2",{children:"Design"}),Object(n.jsx)(he,{})]})}},"/cv.html":{title:"CV",shortTitle:"CV",component:function(){return Object(n.jsx)(Se,{title:"CV",children:Object(n.jsx)("iframe",{src:"/data/Zihan Yan_CV_202103.pdf",style:{width:"100%",height:"90vh"}})})}},"/publication/":{title:"Publication",shortTitle:"Publication",component:function(){return Object(n.jsx)(Se,{title:"Publications",children:Object(n.jsx)(pe,{})})}}},function(e){for(var t={},i=function(){var i=r[a];t["".concat(e).concat(i.shortName,".html")]={component:function(){return Object(n.jsxs)(Se,{title:i.name,children:[Object(n.jsx)(b.b,{to:e,children:"Show All Publications"}),Object(n.jsx)("h2",{children:i.name}),Object(n.jsx)("p",{children:i.writer}),Object(n.jsx)("img",{style:{maxWidth:"100%"},src:i.image,alt:i.shortName}),Object(n.jsx)("h3",{children:"Abstract"}),Object(n.jsx)("p",{style:{textAlign:"justify"},children:i.abstract}),Object(n.jsx)(b.b,{to:e,children:"Show All Publications"})]})}}},a=0,r=de;a<r.length;a++)i();return t}("/publication/")),{},{"/design/":{title:"Design",shortTitle:"Design",component:function(){return Object(n.jsxs)(Se,{title:"Design",children:[Object(n.jsx)("h2",{children:"Design"}),Object(n.jsx)(he,{})]})}},"/design/bamboo.html":{component:function(){return Object(n.jsxs)(Se,{title:"Design",children:[Object(n.jsx)(b.b,{to:"/design/",children:"Show All Designs"}),Object(n.jsx)("h3",{children:"Bamboo Shoot (A Soil Remediation Product Used Industrial Wastes)"}),Object(n.jsx)("p",{children:"Qianya Lou, Jingchen An, Kaiqi Jiang, Zihan Yan"}),Object(n.jsx)("img",{style:{maxWidth:"100%"},src:ne,alt:"bamboo2"}),Object(n.jsx)("h4",{children:"Introduction"}),Object(n.jsx)("p",{children:"Bamboo shoots, which give people the hope of green life by the upward growth posture, is a design to deal with heavy metals and organic soil pollution. Nowadays, the standard rate of the national total soil point exceeding is 16.1%, so the soil recovery needs to be highlighted."}),Object(n.jsx)("h4",{children:"Jury Statement"}),Object(n.jsx)("p",{children:"Bamboo Shoot is an interesting proposal with great application potential. The proposal solves several problems related to soil restoration."}),Object(n.jsx)(b.b,{to:"/design/",children:"Show All Designs"})]})}},"/hobby.html":{title:"Hobby",shortTitle:"Hobby",component:function(){return Object(n.jsxs)(Se,{title:"Hobby",children:[Object(n.jsx)("h2",{children:"Martial Art"}),Object(n.jsx)("p",{children:"Member of Chinese Martial Arts Association"}),Object(n.jsx)("img",{style:{maxWidth:"100%"},src:W,alt:"my material art skill"}),Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"The 14th Hong Kong International Martial Arts Competition, First prize of Traditional Bajiquan (2019)"}),Object(n.jsx)("li",{children:"The 14th Hong Kong International Martial Arts Competition, First prize of Pictographic boxing (2019)"}),Object(n.jsx)("li",{children:"Chinese College Students Martial Arts Championship, Fourth prize of Soft Instruments (2019)"}),Object(n.jsx)("li",{children:"Chinese College Students Martial Arts Championship, Fourth prize of Pictographic boxing (2019)"})]}),Object(n.jsx)("h2",{children:"Calligraphy"}),Object(n.jsx)("img",{style:{maxWidth:"39.29%"},src:L,alt:"my calligraphy #1"}),Object(n.jsx)("img",{style:{maxWidth:"60.71%"},src:P,alt:"my calligraphy #2"}),Object(n.jsx)("h2",{children:"Painting"}),Object(n.jsx)("h3",{children:"Watercolour"}),Object(n.jsx)("img",{style:{maxWidth:"100%"},src:H,alt:"my painting #1"}),Object(n.jsx)("h3",{children:"Pancel Sketch"}),Object(n.jsx)("img",{style:{maxWidth:"50.76%"},src:R,alt:"my sketch #1"}),Object(n.jsx)("img",{style:{maxWidth:"49.24%"},src:Y,alt:"my sketch #2"})]})}}}),fe=i(45),xe=i(32),ve=i(46);fe.a.add(xe.b,xe.a,ve.a);var Oe=[m,p],ye=Object(x.a)({imgContainer:(me={width:"40%",float:"left",overflow:"hidden",marginRight:20},Object(h.a)(me,"@media (max-width: ".concat(k(0),"px)"),{display:"block",float:"none",width:"100%",maxWidth:1*C(0),margin:[[0,"auto"]]}),Object(h.a)(me,"&:not($largeImage)",{maxWidth:.66666*C(0),outline:"1px solid #333",outlineOffset:0}),me),imgSubContainer:{width:"100%",position:"relative",height:0,padding:0,paddingBottom:"65%","$largeImage &":{paddingBottom:"100%"}},img:{objectFit:"cover",position:"absolute",height:"100%",minHeight:"100%",minWidth:"100%"},largeImage:{},container:{marginTop:10,marginBottom:10,clear:"both","&>p":{textAlign:"justify",textAlignLast:"auto"},"&::after":{content:'""',display:"block",clear:"both"}}});function we(e){var t=ye(),i=e.className,a=e.children,r=e.alt,s=e.allowLargeImage,o=e.containerStyle,c=Object(d.a)(e,["className","children","alt","allowLargeImage","containerStyle"]);return Object(n.jsxs)("div",{className:t.container,style:o,children:[Object(n.jsx)("div",{className:[t.imgContainer,s?t.largeImage:void 0].join(" "),children:Object(n.jsx)("div",{className:t.imgSubContainer,children:Object(n.jsx)("img",Object(l.a)({className:[i,t.img,s?t.largeImage:void 0].join(" "),alt:r},c))})}),a]})}var ke=Object(x.a)({"@global":{body:{minWidth:C(0)},b:{fontWeight:700},a:{color:"inherit","main &":{color:"#3c88d4",textDecoration:"none",transition:"color 0.5s linear","&[data-stay-black]":{color:"#000000"},"&[data-stay-black]:hover":{color:"#e53935"},"&:hover":{color:"#e53935"}}}},originalName:{fontSize:"0.6em",fontWeight:"normal",display:"inline-block",margin:10,fontStyle:"normal","&:before":{content:'"("',display:"inline"},"&:after":{content:'")"',display:"inline"}},"@keyframes gradient":{from:{backgroundPosition:[["0%","50%"]]},"50%":{backgroundPosition:[["100%","50%"]]},to:{backgroundPosition:[["0%","50%"]]}},header:{background:"linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab)",color:"white",backgroundSize:[["400%","400%"]],animation:"$gradient 15s ease infinite",padding:40,"& h1, & p":{margin:0,padding:0}},stuck:{},navBar:{transition:"0.2s","& ul":{display:"flex",flexFlow:[["row","wrap"]],listStyleType:"none",padding:0,margin:0},"& li":{display:"inline-block"},"&:not($navBarFloating)":{background:"transparent",margin:[[20,0,-40,-20]],opacity:1,"$stuck&":{opacity:0}}},navBarFloating:{position:"fixed",left:0,top:0,right:0,zIndex:99999,background:"#000000",opacity:0,"$stuck&":{opacity:1}},navButton:{cursor:"pointer",transition:"0.1s",background:"transparent",display:"inline-block",padding:[[15,20]],"&:hover":{background:"rgba(204,204,204,0.5)"}},framework:{},footer:{background:"linear-gradient(to bottom right, #50a3a2 0%, #53e3a6 100%)",fallback:{background:"#50a3a2"},color:"white",position:"relative",padding:40,display:"flex",justifyContent:"space-between","&>div":{display:"block"},"& h3, & p":{marginTop:0}},footerBg:{position:"absolute",top:0,left:0,width:"100%",height:"100%",zIndex:1,pointerEvents:"none",margin:0,padding:0,overflow:"hidden","& li":{position:"absolute",listStyle:"none",display:"block",width:40,height:40,backgroundColor:"rgba(255,255,255,0.15)",bottom:-160,animation:"$square 25s infinite",transitionTimingFunction:"linear","&:nth-child(1)":{left:"10%"},"&:nth-child(2)":{left:"20%",width:80,height:80,animationDelay:"2s",animationDuration:"17s"},"&:nth-child(3)":{left:"25%",animationDelay:"4s"},"&:nth-child(4)":{left:"40%",width:60,height:60,animationDuration:"22s",backgroundColor:"rgba(255,255,255,0.25)"},"&:nth-child(5)":{left:"70%"},"&:nth-child(6)":{left:"80%",width:120,height:120,animationDelay:"3s",backgroundColor:"rgba(255,255,255,0.20)"},"&:nth-child(7)":{left:"32%",width:160,height:160,animationDelay:"7s"},"&:nth-child(8)":{left:"55%",width:20,height:20,animationDelay:"15s",animationDuration:"40s"},"&:nth-child(9)":{left:"25%",width:10,height:10,animationDelay:"2s",animationDuration:"40s",backgroundColor:"rgba(255,255,255,0.30)"},"&:nth-child(10)":{left:"90%",width:160,height:160,animationDelay:"11s"}}},"@keyframes square":{from:{transform:"translateY(0)"},to:{transform:"translateY(-700px) rotate(600deg)"}},pageContainer:{position:"relative",transition:"0.3s"},pageEnter:{position:"absolute",left:0,right:0,top:0,opacity:1},pageExit:{position:"absolute",left:0,right:0,top:0,opacity:0}}),Ce=Object(x.a)({outerContainer:{transition:"0.3s",minHeight:"30vh",fallback:{minHeight:"300px"},padding:20},pageContentWrapper:{maxWidth:k(2),margin:[[0,"auto"]]}});function Se(e){var t=Ce(),i=e.title,a=e.className,r=e.children,s=Object(d.a)(e,["title","className","children"]);return Object(n.jsx)("div",Object(l.a)(Object(l.a)({className:[t.outerContainer,a].join(" ")},s),{},{children:Object(n.jsxs)("div",{className:t.pageContentWrapper,children:[Object(n.jsx)(g.a,{title:i}),r]})}))}var Ne=function(){var e=ke(),t=Object(r.useState)(document.body.clientWidth),i=Object(c.a)(t,2),a=i[0],s=i[1],o=Object(r.useRef)(null),l=Object(r.useState)(!1),d=Object(c.a)(l,2),h=d[0],p=d[1];Object(r.useEffect)((function(){var e=function(e){s(document.body.clientWidth)};return window.addEventListener("resize",e),function(){return window.removeEventListener("resize",e)}})),Object(r.useEffect)((function(){var e=function(){o.current&&p(o.current.getBoundingClientRect().top<=1)};e();var t=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:100,i=null;return function(){for(var a=arguments.length,n=new Array(a),r=0;r<a;r++)n[r]=arguments[r];i||(i=setTimeout((function(){e.apply(void 0,n),i=null}),t))}}(e,50);return window.addEventListener("resize",t),window.addEventListener("scroll",t),function(){window.removeEventListener("resize",t),window.removeEventListener("scroll",t)}}));var m,x=(m=a,w.findIndex((function(e){return m<=e}))),v=["Collage of Computer Science","Collage of Computer Science | Zhejiang University","Collage of Computer Science and Technology | Zhejiang University","Collage of Computer Science and Technology | Zhejiang University","Collage of Computer Science and Technology | Zhejiang University"],O=x<1?"shortTitle":"title",y=Object(n.jsx)("ul",{children:Object.keys(je).filter((function(e){return!!je[e].title})).map((function(t){return Object(n.jsx)("li",{children:Object(n.jsx)(b.b,{to:t,className:e.navButton,children:je[t][O]})},t)}))});return Object(n.jsx)(u.b,{render:function(t){var i=t.location;return Object(n.jsxs)(S.Provider,{value:x,children:[Object(n.jsxs)("div",{className:e.framework,children:[Object(n.jsx)(g.a,{children:Oe.map((function(e){return Object(n.jsx)("link",{rel:"prefetch",href:e},e)}))}),Object(n.jsxs)("header",{className:e.header,children:[Object(n.jsx)("h1",{children:"Zihan Yan "}),Object(n.jsx)("p",{children:v[x]}),Object(n.jsx)("nav",{ref:o,className:[e.navBar,h?e.stuck:void 0].join(" "),children:y}),Object(n.jsx)("nav",{className:[e.navBar,e.navBarFloating,h?e.stuck:void 0].join(" "),children:y})]}),Object(n.jsx)(j.a,{component:"main",className:e.pageContainer,children:Object(n.jsx)(f.a,{classNames:{enter:e.pageEnter,exit:e.pageExit},timeout:1,children:Object(n.jsxs)(u.d,{location:i,children:[A(),Object.keys(je).map((function(e){return Object(n.jsx)(u.b,{exact:!0,path:e,component:je[e].component},e)})),Object(n.jsx)(u.b,{render:function(){return Object(n.jsx)(u.a,{to:"/"})}})]},i.pathname)},i.pathname)})]}),Object(n.jsxs)("footer",{className:e.footer,children:[Object(n.jsxs)("div",{children:[Object(n.jsx)("h3",{children:"Contact Information"}),Object(n.jsx)("p",{children:Object(n.jsx)("a",{href:"mailto:zihanyan@zju.edu.cn",children:"zihanyan@zju.edu.cn"})})]}),Object(n.jsx)("div",{style:{display:void 0},children:Object(n.jsx)("p",{children:"\xa9 2020 Zihan"})}),Object(n.jsxs)("ul",{className:e.footerBg,style:{clear:"both"},children:[Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{}),Object(n.jsx)("li",{})]})]})]})}})},Te=function(e){e&&e instanceof Function&&i.e(3).then(i.bind(null,289)).then((function(t){var i=t.getCLS,a=t.getFID,n=t.getFCP,r=t.getLCP,s=t.getTTFB;i(e),a(e),n(e),r(e),s(e)}))};x.b.setup({id:{minify:"production".startsWith("production")}}),Object(o.render)(Object(n.jsx)(s.a.StrictMode,{children:Object(n.jsx)(b.a,{basename:void 0,children:Object(n.jsx)(Ne,{})})}),document.getElementById("root")),Te()},56:function(e,t,i){}},[[283,1,2]]]);
//# sourceMappingURL=main.a5e312a2.chunk.js.map